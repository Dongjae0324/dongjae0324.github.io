---
---


@STRING{CVPR = {Proc. IEEE Conf. on Computer Vision and Pattern	Recognition (CVPR)}}
@STRING{ECCV = {Proc. of the European Conf. on Computer Vision (ECCV)}}
@STRING{ICCV = {Proc. of the IEEE International Conf. on Computer Vision (ICCV)}}
@STRING{THREEDV = {Proc. of the International Conf. on 3D Vision (3DV)}}
@STRING{NEURIPS = {Advances in Neural Information Processing Systems (NeurIPS)}}
@STRING{NEURIPSW = {Advances in Neural Information Processing Systems (NeurIPS) Workshop}}
@STRING{ARXIV = {arXiv.org}}
@STRING{AAAIW = {Proc. of the Association for the Advancement of Artificial Intelligence (AAAI) Workshop}}
@STRING{ICLR = {Proc. of the International Conf. on Learning Representations (ICLR)}}

@inproceedings{kim2025rainbow,
  title={Rainbow Padding: Mitigating Early Termination In Instruction-tuned Diffusion LLMs},
  author = {Kim, Bumjun and Jeon, Dongjae and Kim, Dueun and Jeung, Wonje and No, Albert},
  coauthor={Bumjun Kim, Dongjae Jeon, Dueun Kim},
  booktitle  = {ICLR},
  year      = {2026},
  pub_id = {C7},
  html = {https://arxiv.org/abs/2510.03680},
  prjpage={https://ai-isl.github.io/rainbow-padding},
  img = {https://dongjae0324.github.io/assets/img/publications/rainbow.jpg},
  tags = {DGMs},
  code= {https://github.com/quasar529/rainbow-padding},
  tldr = {This paper identifies  overflow in instruction tuned diffusion LLMs, where increasing the max length paradoxically causes early termination or repetitive  outputs because  serves as both padding and the stop token. It proposes Rainbow Padding, which replaces repeated  padding with a small cyclic set of distinct padding tokens, restoring length robustness and improving reasoning and coding performance with minimal LoRA fine tuning.},
}

@inproceedings{jeung2025a2d,
  title={A2D: Any-Order, Any-Step Safety Alignment for Diffusion Language Models},
  author = {Jeung, Wonje and Yoon, Sangyeon and Cho, Yoonjun and Jeon, Dongjae and Shin, Sangwoo and Hong, Hyesoo and No, Albert},
  coauthor={Wonje Jeung, Sangyeon Yoon},
  booktitle  = {ICLR},
  year      = {2026},
  pub_id = {C6},
  html = {https://www.arxiv.org/abs/2509.23286},
  img = {https://dongjae0324.github.io/assets/img/publications/a2d.jpg},
  tags = {Safety, DGMs},
  tldr = {This paper proposes A2D, a token-level safety alignment method for diffusion language models that triggers an \texttt{[EOS]} refusal as soon as harmful content arises, making safety robust to any decoding order and any step. On safety benchmarks, A2D drives DIJA prefilling attack success rates from over 80% to near-zero and enables early rejection via thresholded \texttt{[EOS]} probabilities for up to 19.3$\times$ faster safe termination.},
}


@inproceedings{jeon2024information,
  title={An Information Theoretic Metric for Evaluating Unlearning Models},
  author={Jeon, Dongjae and Jeung, Wonje and Kim, Taeheon and No, Albert and Choi, Jonghyun},
  coauthor={Dongjae Jeon, Wonje Jeung},
  booktitle  = {AAAI},
  year      = {2026},
  pub_id = {C5},
  html = {https://arxiv.org/abs/2405.17878},
  img = {https://dongjae0324.github.io/assets/img/publications/idi2.jpg},
  tags = {Safety},
  tldr = {This paper introduces the Information Difference Index (IDI), a white box information theoretic metric that quantifies residual forget set information retained in intermediate representations after unlearning, beyond what end task accuracy reveals. Across datasets and architectures, IDI exposes cases where black box evaluations overestimate unlearning and provides a more reliable measure of strong unlearning.},
}

@inproceedings{jeon2025infodiff,
  title={Information-Theoretic Discrete Diffusion},
  author = {Jeon, Moongyu and Shin, Sangwoo and Jeon, Dongjae and No, Albert},
  coauthor={},
  booktitle  = {NeurIPS},
  year      = {2025},
  pub_id = {C4},
  html = {https://arxiv.org/abs/2510.24088},
  img = {https://dongjae0324.github.io/assets/img/publications/info_dd.png},
  code = {https://github.com/Dongjae0324/infodis},
  tags = {DGMs},
  tldr = {This paper develops an information theoretic foundation for discrete diffusion, deriving I MDSE and I MDCE identities that show common score matching losses (DSE and DCE) yield tight, principled log likelihood estimators rather than loose variational bounds. It also provides practical estimators, including a time free likelihood formula, conditional likelihood for prompt response tasks, and a coupled Monte Carlo likelihood ratio estimator, with experiments validating accuracy and variance stability.},
}

@inproceedings{cho2025Assigning,
  title={Assigning Distinct Roles to Quantized and Low-Rank Matrices Toward Optimal Weight Decomposition},
  author = {Cho, Yoonjun and Kim, Soeun and Jeon, Dongjae and Lee, Kyelim and Lee, Beomsoo and No, Albert},
  coauthor={},
  booktitle  = {ACL Findings},
  year      = {2025},
  pub_id = {C3},
  html = {https://arxiv.org/abs/2506.02077},
  img = {https://dongjae0324.github.io/assets/img/publications/odlri.jpg},
  tags = {Efficient ML},
  tldr = {This paper shows that joint quantization plus low rank decomposition quality depends strongly on how the low rank term is initialized, because initialization fixes the roles each component keeps during optimization; it proposes Outlier Driven Low Rank Initialization (ODLRI) that assigns activation sensitive outlier weights to the low rank part so quantization handles the remaining weights more stably. Experiments on Llama2, Llama3, and Mistral show consistent gains in activation aware error, quantization scale, perplexity, and zero shot accuracy in extreme low bit settings.},
}

@inproceedings{jeon2024understanding,
  title={Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes},
  author={Jeon, Dongjae and Kim, Dueun and No, Albert},
  coauthor={Dongjae Jeon, Dueun Kim},
  booktitle  = {ICML},
  year      = {2025},
  pub_id = {C2},
  award = {Spotlight},
  prev_booktitle = {AAAI (PPAI workshop)},
  prev_year = {2025},
  prev_award = {Oral},
  html = {https://arxiv.org/abs/2412.04140},
  slides = {https://dongjae0324.github.io/assets/pdf/icml25_memorization_slide.pdf},
  code = {https://github.com/Dongjae0324/sharpness_memorization_diffusion},
  img = {https://dongjae0324.github.io/assets/img/publications/hessian.jpg},
  tags = {Safety, DGMs},
  tldr = {
This paper links diffusion model memorization to high sharpness in the learned log-density landscape and proposes a sharpness-based metric that detects memorization from the earliest sampling steps; it then introduces SAIL, an inference-time initial-noise optimization that steers sampling toward smoother regions to reduce memorization without retraining or prompt edits.
  },
}

@inproceedings{jeung2024large,
  title={Large Language Models Still Exhibit Bias in Long Text},
  author={Jeung, Wonje and Jeon, Dongjae and Yousefpour, Ashkan and Choi, Jonghyun},
  coauthor={},
  booktitle={ACL Findings},
  year={2025},
  pub_id = {C1},
  prev_booktitle = {NeurIPS (SOLAR workshop)},
  prev_year = {2024},
  html = {https://arxiv.org/abs/2410.17519},
  img = {https://dongjae0324.github.io/assets/img/publications/bias.jpg},
  tags = {Safety},
  tldr = {This paper introduces LTF TEST, a long form fairness benchmark that probes demographic bias in essay style generations across 14 topics and 10 demographic axes. Evaluations on multiple LLMs show that bias remains and can surface more clearly in long text than in short form fairness tests, motivating long form bias auditing as a complementary standard.},
}