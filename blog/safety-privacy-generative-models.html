<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Safety and Privacy in Generative Models - Dongjae Jeon</title>
    <link rel="icon" type="image/x-icon" href="../favicon.ico">
    
    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,400;0,600;0,700;1,400&display=swap" rel="stylesheet">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
    :root {
        --primary: #222;
        --accent: #0066cc;
        --accent-hover: #004499;
        --muted: #555;
        --light-bg: #f5f5f5;
        --border: #ddd;
        --white: #ffffff;
    }
    
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
        font-size: 14px;
        line-height: 1.5;
        color: var(--primary);
        background: var(--white);
        min-height: 100vh;
    }
    
    a {
        color: var(--accent);
        text-decoration: none;
        transition: color 0.2s ease;
    }
    
    a:hover {
        color: var(--accent-hover);
    }
    
    /* Navigation */
    .navbar {
        background: var(--white);
        padding: 0.75rem 0;
        border-bottom: 1px solid var(--border);
        position: sticky;
        top: 0;
        z-index: 1000;
    }
    
    .nav-container {
        max-width: 1100px;
        margin: 0 auto;
        padding: 0 2rem;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    
    .nav-brand {
        font-weight: 600;
        font-size: 1rem;
        color: var(--primary);
    }
    
    .nav-links {
        display: flex;
        gap: 1.25rem;
    }
    
    .nav-links a {
        color: var(--muted);
        font-size: 0.85rem;
    }
    
    .nav-links a:hover,
    .nav-links a.active {
        color: var(--accent);
    }
    
    .container {
        max-width: 1100px;
        margin: 0 auto;
        padding: 1.5rem 2rem;
    }
    
    .blog-post {
        margin-top: 3rem;
        margin-bottom: 3rem;
        max-width: 850px;
    }
    
    .post-header {
        margin-bottom: 2rem;
        border-bottom: 1px solid var(--border);
        padding-bottom: 1.5rem;
    }
    
    .post-title {
        font-size: 2rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        color: var(--primary);
    }
    
    .post-meta {
        font-size: 0.9rem;
        color: var(--muted);
    }
    
    .post-content {
        font-size: 0.95rem;
        line-height: 1.8;
        color: #333;
    }
    
    .post-content h2 {
        font-size: 1.3rem;
        font-weight: 600;
        margin-top: 1.5rem;
        margin-bottom: 0.75rem;
        color: var(--primary);
    }
    
    .post-content h3 {
        font-size: 1.1rem;
        font-weight: 600;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        color: var(--primary);
    }
    
    .post-content p {
        margin-bottom: 1rem;
    }
    
    .post-content ul {
        margin-left: 1.5rem;
        margin-bottom: 1rem;
    }
    
    .post-content li {
        margin-bottom: 0.5rem;
    }
    
    .post-content code {
        background: var(--light-bg);
        padding: 0.2rem 0.4rem;
        border-radius: 3px;
        font-family: monospace;
        font-size: 0.9em;
    }
    
    .post-content pre {
        background: var(--light-bg);
        padding: 1rem;
        border-radius: 5px;
        overflow-x: auto;
        margin-bottom: 1rem;
    }
    
    .post-content pre code {
        background: none;
        padding: 0;
    }
    
    .back-link {
        display: inline-block;
        margin-bottom: 1rem;
        font-size: 0.9rem;
    }
    
    .footer {
        text-align: center;
        padding: 1rem;
        color: var(--muted);
        font-size: 0.8rem;
        border-top: 1px solid var(--border);
        margin-top: 1.5rem;
    }
    </style>
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-container">
            <a href="../index.html" class="nav-brand">Dongjae Jeon</a>
            <div class="nav-links">
                <a href="../index.html#about">About</a>
                <a href="../index.html#publications">Publications</a>
                <a href="../index.html#awards">Awards</a>
                <a href="../index.html#blog">Blog</a>
            </div>
        </div>
    </nav>
    
    <div class="container">
        <article class="blog-post">
            <a href="../index.html#blog" class="back-link">← Back to blog</a>
            
            <div class="post-header">
                <h1 class="post-title">Safety and Privacy in Generative Models</h1>
                <div class="post-meta">Published on December 2025</div>
            </div>
            
            <div class="post-content">
                <p>As generative models become increasingly powerful and widely deployed, concerns about safety and privacy have moved to the forefront of AI research. In this post, we explore key challenges and potential solutions.</p>
                
                <h2>The Memorization Problem</h2>
                <p>One critical issue is that generative models can memorize and reproduce training data, potentially leaking sensitive information. This is particularly concerning for models trained on proprietary or personal data.</p>
                
                <h3>Understanding Memorization</h3>
                <p>Memorization occurs when a model learns exact training examples rather than general patterns. This can happen especially with:</p>
                <ul>
                    <li>Small, high-quality datasets</li>
                    <li>Rare or unique examples</li>
                    <li>Overly complex models</li>
                </ul>
                
                <h2>Privacy-Preserving Techniques</h2>
                
                <h3>Differential Privacy</h3>
                <p>Differential privacy is a mathematical framework that quantifies and limits the amount of information an algorithm can leak about individuals in a dataset. By adding carefully calibrated noise during training, we can ensure privacy guarantees.</p>
                
                <h3>Machine Unlearning</h3>
                <p>Machine unlearning enables models to "forget" specific training examples upon request. This is particularly important for compliance with regulations like GDPR, which includes the right to be forgotten.</p>
                
                <h2>Safety Alignment</h2>
                <p>Beyond privacy, ensuring that generative models produce safe and ethical outputs is crucial. This involves:</p>
                <ul>
                    <li>Training with diverse and representative data</li>
                    <li>Using reinforcement learning from human feedback (RLHF)</li>
                    <li>Implementing robust filtering and moderation</li>
                    <li>Continuous monitoring and evaluation</li>
                </ul>
                
                <h2>Future Directions</h2>
                <p>The field of safe and private generative models is rapidly evolving. Key areas for future research include:</p>
                <ul>
                    <li>More efficient privacy-preserving training methods</li>
                    <li>Better techniques for verifying safety properties</li>
                    <li>Scalable solutions for large models</li>
                    <li>Interdisciplinary approaches combining ML with ethics and policy</li>
                </ul>
                
                <h2>Conclusion</h2>
                <p>Safety and privacy in generative models are not optional extras but fundamental requirements for responsible AI deployment. As these models become more prevalent in society, addressing these concerns will be essential for maintaining public trust and ensuring ethical AI systems.</p>
            </div>
        </article>
    </div>
    
    <footer class="footer">
        <p>© 2026 Dongjae Jeon.</p>
    </footer>
</body>
</html>
